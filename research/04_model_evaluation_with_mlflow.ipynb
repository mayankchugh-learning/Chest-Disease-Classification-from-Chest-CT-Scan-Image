{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\git\\\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\git\\\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('d:\\\\git\\\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\git\\\\Chest-Disease-Classification-from-Chest-CT-Scan-Image'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"]=\"https://dagshub.com/mayankchugh-learning/Chest-Disease-Classification-from-Chest-CT-Scan-Image.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=\"mayankchugh-learning\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\git\\\\Chest-Disease-Classification-from-Chest-CT-Scan-Image'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-15 12:57:57,709: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]\n",
      "[2024-03-15 12:57:57,721: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 12:57:57,734: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 12:57:57,735: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 12:57:57,736: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2024-03-15 12:57:57,737: INFO: data_ingestion: Downloading data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 12:58:08,664: INFO: data_ingestion: Downloaded data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 12:58:10,291: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 12:58:10,291: INFO: main: *******************]\n",
      "[2024-03-15 12:58:10,291: INFO: main: >>>>>> stage Prepare base model started <<<<<<]\n",
      "[2024-03-15 12:58:10,298: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 12:58:10,303: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 12:58:10,305: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 12:58:10,307: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "[2024-03-15 12:58:12,039: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "[2024-03-15 12:58:14,145: INFO: main: >>>>>> stage Prepare base model completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 12:58:14,145: INFO: main: *******************]\n",
      "[2024-03-15 12:58:14,145: INFO: main: >>>>>> stage Training started <<<<<<]\n",
      "[2024-03-15 12:58:14,153: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 12:58:14,157: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 12:58:14,158: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 12:58:14,159: INFO: common: created directory at: artifacts\\training]\n",
      "Found 68 images belonging to 2 classes.\n",
      "Found 275 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "\n",
      " 1/17 [>.............................] - ETA: 2:54 - loss: 0.9607 - accuracy: 0.3125\n",
      " 2/17 [==>...........................] - ETA: 1:59 - loss: 17.4853 - accuracy: 0.3438\n",
      " 3/17 [====>.........................] - ETA: 1:50 - loss: 17.2607 - accuracy: 0.3958\n",
      " 4/17 [======>.......................] - ETA: 1:42 - loss: 16.2806 - accuracy: 0.4531\n",
      " 5/17 [=======>......................] - ETA: 1:36 - loss: 14.5484 - accuracy: 0.4625\n",
      " 6/17 [=========>....................] - ETA: 1:28 - loss: 17.6685 - accuracy: 0.4479\n",
      " 7/17 [===========>..................] - ETA: 1:20 - loss: 17.3230 - accuracy: 0.4554\n",
      " 8/17 [=============>................] - ETA: 1:12 - loss: 18.7078 - accuracy: 0.4297\n",
      " 9/17 [==============>...............] - ETA: 1:04 - loss: 19.3383 - accuracy: 0.4514\n",
      "10/17 [================>.............] - ETA: 56s - loss: 17.7003 - accuracy: 0.4750 \n",
      "11/17 [==================>...........] - ETA: 48s - loss: 17.5743 - accuracy: 0.4716\n",
      "12/17 [====================>.........] - ETA: 37s - loss: 17.5467 - accuracy: 0.4749\n",
      "13/17 [=====================>........] - ETA: 30s - loss: 16.1330 - accuracy: 0.5077\n",
      "14/17 [=======================>......] - ETA: 22s - loss: 15.2811 - accuracy: 0.5213\n",
      "15/17 [=========================>....] - ETA: 15s - loss: 15.0482 - accuracy: 0.5198\n",
      "16/17 [===========================>..] - ETA: 7s - loss: 14.8735 - accuracy: 0.5309 \n",
      "17/17 [==============================] - ETA: 0s - loss: 13.9690 - accuracy: 0.5483\n",
      "17/17 [==============================] - 169s 10s/step - loss: 13.9690 - accuracy: 0.5483 - val_loss: 0.3444 - val_accuracy: 0.8750\n",
      "Epoch 2/2\n",
      "\n",
      " 1/17 [>.............................] - ETA: 2:27 - loss: 0.0770 - accuracy: 1.0000\n",
      " 2/17 [==>...........................] - ETA: 2:06 - loss: 0.2647 - accuracy: 0.9375\n",
      " 3/17 [====>.........................] - ETA: 1:57 - loss: 3.9443 - accuracy: 0.7708\n",
      " 4/17 [======>.......................] - ETA: 1:48 - loss: 9.5840 - accuracy: 0.7031\n",
      " 5/17 [=======>......................] - ETA: 1:39 - loss: 8.8497 - accuracy: 0.6625\n",
      " 6/17 [=========>....................] - ETA: 1:30 - loss: 11.0792 - accuracy: 0.6458\n",
      " 7/17 [===========>..................] - ETA: 1:22 - loss: 9.6477 - accuracy: 0.6429 \n",
      " 8/17 [=============>................] - ETA: 1:13 - loss: 10.7843 - accuracy: 0.6328\n",
      " 9/17 [==============>...............] - ETA: 1:05 - loss: 10.2995 - accuracy: 0.5972\n",
      "10/17 [================>.............] - ETA: 52s - loss: 11.1582 - accuracy: 0.5918 \n",
      "11/17 [==================>...........] - ETA: 45s - loss: 10.6118 - accuracy: 0.5706\n",
      "12/17 [====================>.........] - ETA: 38s - loss: 11.8775 - accuracy: 0.5754\n",
      "13/17 [=====================>........] - ETA: 31s - loss: 11.4127 - accuracy: 0.5744\n",
      "14/17 [=======================>......] - ETA: 23s - loss: 12.2215 - accuracy: 0.5592\n",
      "15/17 [=========================>....] - ETA: 15s - loss: 12.9417 - accuracy: 0.5463\n",
      "16/17 [===========================>..] - ETA: 7s - loss: 12.6643 - accuracy: 0.5597 \n",
      "17/17 [==============================] - ETA: 0s - loss: 12.0208 - accuracy: 0.5637\n",
      "17/17 [==============================] - 170s 10s/step - loss: 12.0208 - accuracy: 0.5637 - val_loss: 11.9775 - val_accuracy: 0.6094\n",
      "[2024-03-15 13:03:57,917: INFO: main: >>>>>> stage Training completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 13:03:57,918: INFO: main: *******************]\n",
      "[2024-03-15 13:03:57,918: INFO: main: >>>>>> stage Evaluation stage started <<<<<<]\n",
      "[2024-03-15 13:03:57,926: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 13:03:57,930: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 13:03:57,933: INFO: common: created directory at: artifacts]\n",
      "Found 102 images belonging to 2 classes.\n",
      "\n",
      "1/7 [===>..........................] - ETA: 58s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "2/7 [=======>......................] - ETA: 45s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "3/7 [===========>..................] - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "4/7 [================>.............] - ETA: 27s - loss: 4.0610 - accuracy: 0.9062    \n",
      "5/7 [====================>.........] - ETA: 17s - loss: 8.5862 - accuracy: 0.7250\n",
      "6/7 [========================>.....] - ETA: 8s - loss: 12.9996 - accuracy: 0.6042\n",
      "7/7 [==============================] - ETA: 0s - loss: 14.1786 - accuracy: 0.5686\n",
      "7/7 [==============================] - 57s 8s/step - loss: 14.1786 - accuracy: 0.5686\n",
      "[2024-03-15 13:04:56,397: INFO: common: json file saved at: scores.json]\n",
      "[2024-03-15 13:04:56,399: INFO: common: json file saved at: scores.json]\n",
      "[2024-03-15 13:05:06,556: WARNING: save: Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.]\n",
      "[2024-03-15 13:05:10,762: INFO: builder_impl: Assets written to: C:\\Users\\mayan\\AppData\\Local\\Temp\\tmp4u3y8sq5\\model\\data\\model\\assets]\n",
      "[2024-03-15 13:06:02,855: INFO: main: >>>>>> stage Evaluation stage completed <<<<<<\n",
      "\n",
      "x==========x]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?/export=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ\n",
      "From (redirected): https://drive.google.com/uc?%2Fexport=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ&confirm=t&uuid=4071b8f9-9aa8-48c7-bf33-b20d5d85c832\n",
      "To: d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\artifacts\\data_ingestion\\data.zip\n",
      "\n",
      "  0%|          | 0.00/49.0M [00:00<?, ?B/s]\n",
      "  2%|▏         | 1.05M/49.0M [00:00<00:06, 7.44MB/s]\n",
      "  4%|▍         | 2.10M/49.0M [00:00<00:06, 7.40MB/s]\n",
      "  6%|▋         | 3.15M/49.0M [00:00<00:06, 7.38MB/s]\n",
      "  9%|▊         | 4.19M/49.0M [00:00<00:06, 7.12MB/s]\n",
      " 11%|█         | 5.24M/49.0M [00:00<00:06, 6.96MB/s]\n",
      " 13%|█▎        | 6.29M/49.0M [00:00<00:06, 6.97MB/s]\n",
      " 15%|█▍        | 7.34M/49.0M [00:01<00:06, 6.89MB/s]\n",
      " 17%|█▋        | 8.39M/49.0M [00:01<00:05, 7.25MB/s]\n",
      " 19%|█▉        | 9.44M/49.0M [00:01<00:05, 7.45MB/s]\n",
      " 21%|██▏       | 10.5M/49.0M [00:01<00:05, 7.42MB/s]\n",
      " 24%|██▎       | 11.5M/49.0M [00:01<00:05, 7.32MB/s]\n",
      " 26%|██▌       | 12.6M/49.0M [00:01<00:05, 7.25MB/s]\n",
      " 28%|██▊       | 13.6M/49.0M [00:01<00:04, 7.17MB/s]\n",
      " 30%|██▉       | 14.7M/49.0M [00:02<00:04, 7.27MB/s]\n",
      " 32%|███▏      | 15.7M/49.0M [00:02<00:04, 7.22MB/s]\n",
      " 34%|███▍      | 16.8M/49.0M [00:02<00:04, 7.54MB/s]\n",
      " 36%|███▋      | 17.8M/49.0M [00:02<00:04, 7.73MB/s]\n",
      " 39%|███▊      | 18.9M/49.0M [00:02<00:03, 7.72MB/s]\n",
      " 41%|████      | 19.9M/49.0M [00:02<00:03, 7.96MB/s]\n",
      " 43%|████▎     | 21.0M/49.0M [00:02<00:03, 7.90MB/s]\n",
      " 45%|████▍     | 22.0M/49.0M [00:02<00:03, 8.04MB/s]\n",
      " 47%|████▋     | 23.1M/49.0M [00:03<00:03, 8.13MB/s]\n",
      " 49%|████▉     | 24.1M/49.0M [00:03<00:03, 8.09MB/s]\n",
      " 51%|█████▏    | 25.2M/49.0M [00:03<00:02, 8.08MB/s]\n",
      " 54%|█████▎    | 26.2M/49.0M [00:03<00:02, 8.05MB/s]\n",
      " 56%|█████▌    | 27.3M/49.0M [00:03<00:02, 7.63MB/s]\n",
      " 58%|█████▊    | 28.3M/49.0M [00:03<00:02, 7.29MB/s]\n",
      " 60%|█████▉    | 29.4M/49.0M [00:03<00:02, 7.48MB/s]\n",
      " 62%|██████▏   | 30.4M/49.0M [00:04<00:02, 7.59MB/s]\n",
      " 64%|██████▍   | 31.5M/49.0M [00:04<00:02, 7.64MB/s]\n",
      " 66%|██████▋   | 32.5M/49.0M [00:04<00:02, 7.61MB/s]\n",
      " 69%|██████▊   | 33.6M/49.0M [00:04<00:02, 7.61MB/s]\n",
      " 71%|███████   | 34.6M/49.0M [00:04<00:01, 7.72MB/s]\n",
      " 73%|███████▎  | 35.7M/49.0M [00:04<00:01, 7.73MB/s]\n",
      " 75%|███████▍  | 36.7M/49.0M [00:04<00:01, 7.67MB/s]\n",
      " 77%|███████▋  | 37.7M/49.0M [00:05<00:01, 7.50MB/s]\n",
      " 79%|███████▉  | 38.8M/49.0M [00:05<00:01, 5.74MB/s]\n",
      " 81%|████████▏ | 39.8M/49.0M [00:05<00:01, 5.85MB/s]\n",
      " 84%|████████▎ | 40.9M/49.0M [00:05<00:01, 6.46MB/s]\n",
      " 86%|████████▌ | 41.9M/49.0M [00:05<00:01, 6.65MB/s]\n",
      " 88%|████████▊ | 43.0M/49.0M [00:05<00:00, 6.98MB/s]\n",
      " 90%|████████▉ | 44.0M/49.0M [00:05<00:00, 7.28MB/s]\n",
      " 92%|█████████▏| 45.1M/49.0M [00:06<00:00, 7.01MB/s]\n",
      " 94%|█████████▍| 46.1M/49.0M [00:06<00:00, 7.12MB/s]\n",
      " 96%|█████████▋| 47.2M/49.0M [00:06<00:00, 7.16MB/s]\n",
      " 99%|█████████▊| 48.2M/49.0M [00:06<00:00, 7.30MB/s]\n",
      "100%|██████████| 49.0M/49.0M [00:06<00:00, 7.34MB/s]\n",
      "2024/03/15 13:04:56 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logged at level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2024/03/15 13:05:00 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'VGG16Model' already exists. Creating a new version of this model...\n",
      "2024/03/15 13:06:02 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: VGG16Model, version 2\n",
      "Created version '2' of model 'VGG16Model'.\n"
     ]
    }
   ],
   "source": [
    "!python main.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"artifacts/training/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConfigurationManager file code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model=\"artifacts/training/model.h5\",\n",
    "            training_data=\"artifacts/data_ingestion/Chest-CT-Scan-data\",\n",
    "            mlflow_uri=\"https://dagshub.com/mayankchugh-learning/Chest-Disease-Classification-from-Chest-CT-Scan-Image.mlflow\",\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE\n",
    "        )\n",
    "        return eval_config\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation component file code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def _valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.30\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> tf.keras.Model:\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "\n",
    "    def evaluation(self):\n",
    "        self.model = self.load_model(self.config.path_of_model)\n",
    "        self._valid_generator()\n",
    "        self.score = model.evaluate(self.valid_generator)\n",
    "        self.save_score()\n",
    "\n",
    "    def save_score(self):\n",
    "        scores = {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "        save_json(path=Path(\"scores.json\"), data=scores)\n",
    "\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics(\n",
    "                {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "            )\n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.keras.log_model(self.model, \"model\", registered_model_name=\"VGG16Model\")\n",
    "            else:\n",
    "                mlflow.keras.log_model(self.model, \"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stage 04 Model Evalution pipeline file code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-15 11:28:15,103: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 11:28:15,112: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 11:28:15,115: INFO: common: created directory at: artifacts]\n",
      "Found 102 images belonging to 2 classes.\n",
      "7/7 [==============================] - 79s 11s/step - loss: 6.5524 - accuracy: 0.4314\n",
      "[2024-03-15 11:29:37,248: INFO: common: json file saved at: scores.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/15 11:29:39 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logged at level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2024/03/15 11:29:44 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-15 11:29:54,319: WARNING: save: Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\mayan\\AppData\\Local\\Temp\\tmph3ikgioy\\model\\data\\model\\assets\n",
      "[2024-03-15 11:29:59,419: INFO: builder_impl: Assets written to: C:\\Users\\mayan\\AppData\\Local\\Temp\\tmph3ikgioy\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'VGG16Model'.\n",
      "2024/03/15 11:31:07 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: VGG16Model, version 1\n",
      "Created version '1' of model 'VGG16Model'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_evaluation_config()\n",
    "    evaluation = Evaluation(eval_config)\n",
    "    evaluation.evaluation()\n",
    "    evaluation.log_into_mlflow()\n",
    "\n",
    "except Exception as e:\n",
    "   raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-15 13:07:54,235: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]\n",
      "[2024-03-15 13:07:54,238: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 13:07:54,244: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 13:07:54,249: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 13:07:54,250: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2024-03-15 13:07:54,251: INFO: data_ingestion: Downloading data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 13:08:04,049: INFO: data_ingestion: Downloaded data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 13:08:05,829: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 13:08:05,830: INFO: main: *******************]\n",
      "[2024-03-15 13:08:05,830: INFO: main: >>>>>> stage Prepare base model started <<<<<<]\n",
      "[2024-03-15 13:08:05,838: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 13:08:05,843: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 13:08:05,844: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 13:08:05,845: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "[2024-03-15 13:08:07,288: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "[2024-03-15 13:08:10,720: INFO: main: >>>>>> stage Prepare base model completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 13:08:10,720: INFO: main: *******************]\n",
      "[2024-03-15 13:08:10,721: INFO: main: >>>>>> stage Training started <<<<<<]\n",
      "[2024-03-15 13:08:10,725: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 13:08:10,728: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 13:08:10,729: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 13:08:10,729: INFO: common: created directory at: artifacts\\training]\n",
      "Found 68 images belonging to 2 classes.\n",
      "Found 275 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "\n",
      " 1/17 [>.............................] - ETA: 4:01 - loss: 0.7933 - accuracy: 0.4375\n",
      " 2/17 [==>...........................] - ETA: 5:14 - loss: 7.8377 - accuracy: 0.5312\n",
      " 3/17 [====>.........................] - ETA: 3:28 - loss: 6.7834 - accuracy: 0.5625\n",
      " 4/17 [======>.......................] - ETA: 2:41 - loss: 8.7192 - accuracy: 0.5781\n",
      " 5/17 [=======>......................] - ETA: 2:18 - loss: 8.9631 - accuracy: 0.5125\n",
      " 6/17 [=========>....................] - ETA: 1:57 - loss: 17.0149 - accuracy: 0.4896\n",
      " 7/17 [===========>..................] - ETA: 1:31 - loss: 16.5071 - accuracy: 0.5051\n",
      " 8/17 [=============>................] - ETA: 1:19 - loss: 15.9875 - accuracy: 0.4957\n",
      " 9/17 [==============>...............] - ETA: 1:08 - loss: 16.3936 - accuracy: 0.5115\n",
      "10/17 [================>.............] - ETA: 58s - loss: 14.6199 - accuracy: 0.5646 \n",
      "11/17 [==================>...........] - ETA: 49s - loss: 13.1988 - accuracy: 0.6074\n",
      "12/17 [====================>.........] - ETA: 40s - loss: 12.4117 - accuracy: 0.5922\n",
      "13/17 [=====================>........] - ETA: 32s - loss: 13.7998 - accuracy: 0.5897\n",
      "14/17 [=======================>......] - ETA: 23s - loss: 12.8220 - accuracy: 0.6066\n",
      "15/17 [=========================>....] - ETA: 15s - loss: 13.4551 - accuracy: 0.5815\n",
      "16/17 [===========================>..] - ETA: 7s - loss: 14.0228 - accuracy: 0.5885 \n",
      "17/17 [==============================] - ETA: 0s - loss: 14.1232 - accuracy: 0.5753\n",
      "17/17 [==============================] - 169s 10s/step - loss: 14.1232 - accuracy: 0.5753 - val_loss: 32.9839 - val_accuracy: 0.3906\n",
      "Epoch 2/2\n",
      "\n",
      " 1/17 [>.............................] - ETA: 2:07 - loss: 37.7123 - accuracy: 0.3125\n",
      " 2/17 [==>...........................] - ETA: 1:37 - loss: 27.5191 - accuracy: 0.3750\n",
      " 3/17 [====>.........................] - ETA: 1:36 - loss: 25.7790 - accuracy: 0.3958\n",
      " 4/17 [======>.......................] - ETA: 1:27 - loss: 24.1146 - accuracy: 0.3906\n",
      " 5/17 [=======>......................] - ETA: 1:23 - loss: 24.2989 - accuracy: 0.4125\n",
      " 6/17 [=========>....................] - ETA: 1:16 - loss: 20.8289 - accuracy: 0.4583\n",
      " 7/17 [===========>..................] - ETA: 1:08 - loss: 19.9945 - accuracy: 0.4375\n",
      " 8/17 [=============>................] - ETA: 1:01 - loss: 20.4999 - accuracy: 0.4609\n",
      " 9/17 [==============>...............] - ETA: 53s - loss: 18.5866 - accuracy: 0.4861 \n",
      "10/17 [================>.............] - ETA: 46s - loss: 17.9062 - accuracy: 0.4750\n",
      "11/17 [==================>...........] - ETA: 39s - loss: 18.0557 - accuracy: 0.4886\n",
      "12/17 [====================>.........] - ETA: 33s - loss: 16.5756 - accuracy: 0.5208\n",
      "13/17 [=====================>........] - ETA: 24s - loss: 16.3206 - accuracy: 0.5282\n",
      "14/17 [=======================>......] - ETA: 18s - loss: 15.0832 - accuracy: 0.5640\n",
      "15/17 [=========================>....] - ETA: 12s - loss: 14.0481 - accuracy: 0.5859\n",
      "16/17 [===========================>..] - ETA: 6s - loss: 13.5089 - accuracy: 0.5679 \n",
      "17/17 [==============================] - ETA: 0s - loss: 15.3370 - accuracy: 0.5598\n",
      "17/17 [==============================] - 133s 8s/step - loss: 15.3370 - accuracy: 0.5598 - val_loss: 0.0920 - val_accuracy: 0.9844\n",
      "[2024-03-15 13:13:16,089: INFO: main: >>>>>> stage Training completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 13:13:16,089: INFO: main: *******************]\n",
      "[2024-03-15 13:13:16,089: INFO: main: >>>>>> stage Evaluation stage started <<<<<<]\n",
      "[2024-03-15 13:13:16,094: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 13:13:16,096: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 13:13:16,096: INFO: common: created directory at: artifacts]\n",
      "Found 102 images belonging to 2 classes.\n",
      "\n",
      "1/7 [===>..........................] - ETA: 37s - loss: 0.3413 - accuracy: 0.9375\n",
      "2/7 [=======>......................] - ETA: 33s - loss: 0.1804 - accuracy: 0.9688\n",
      "3/7 [===========>..................] - ETA: 25s - loss: 0.1490 - accuracy: 0.9583\n",
      "4/7 [================>.............] - ETA: 18s - loss: 0.1164 - accuracy: 0.9688\n",
      "5/7 [====================>.........] - ETA: 12s - loss: 0.0931 - accuracy: 0.9750\n",
      "6/7 [========================>.....] - ETA: 6s - loss: 0.0776 - accuracy: 0.9792 \n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.9804\n",
      "7/7 [==============================] - 40s 6s/step - loss: 0.0730 - accuracy: 0.9804\n",
      "[2024-03-15 13:13:56,969: INFO: common: json file saved at: scores.json]\n",
      "[2024-03-15 13:13:56,972: INFO: common: json file saved at: scores.json]\n",
      "[2024-03-15 13:14:01,673: WARNING: save: Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.]\n",
      "[2024-03-15 13:14:03,372: INFO: builder_impl: Assets written to: C:\\Users\\mayan\\AppData\\Local\\Temp\\tmpd819rdab\\model\\data\\model\\assets]\n",
      "[2024-03-15 13:14:38,438: INFO: main: >>>>>> stage Evaluation stage completed <<<<<<\n",
      "\n",
      "x==========x]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?/export=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ\n",
      "From (redirected): https://drive.google.com/uc?%2Fexport=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ&confirm=t&uuid=112a6bcd-44fc-4d6e-b1e2-9eb79d5bf4fd\n",
      "To: d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\artifacts\\data_ingestion\\data.zip\n",
      "\n",
      "  0%|          | 0.00/49.0M [00:00<?, ?B/s]\n",
      "  2%|▏         | 1.05M/49.0M [00:00<00:07, 6.84MB/s]\n",
      "  4%|▍         | 2.10M/49.0M [00:00<00:06, 7.21MB/s]\n",
      "  6%|▋         | 3.15M/49.0M [00:00<00:06, 6.77MB/s]\n",
      "  9%|▊         | 4.19M/49.0M [00:00<00:06, 6.99MB/s]\n",
      " 11%|█         | 5.24M/49.0M [00:00<00:05, 7.42MB/s]\n",
      " 13%|█▎        | 6.29M/49.0M [00:00<00:05, 7.42MB/s]\n",
      " 15%|█▍        | 7.34M/49.0M [00:01<00:05, 7.11MB/s]\n",
      " 17%|█▋        | 8.39M/49.0M [00:01<00:05, 7.32MB/s]\n",
      " 19%|█▉        | 9.44M/49.0M [00:01<00:05, 7.44MB/s]\n",
      " 21%|██▏       | 10.5M/49.0M [00:01<00:04, 7.74MB/s]\n",
      " 24%|██▎       | 11.5M/49.0M [00:01<00:04, 7.92MB/s]\n",
      " 26%|██▌       | 12.6M/49.0M [00:01<00:04, 7.90MB/s]\n",
      " 28%|██▊       | 13.6M/49.0M [00:01<00:04, 8.08MB/s]\n",
      " 30%|██▉       | 14.7M/49.0M [00:01<00:04, 8.05MB/s]\n",
      " 32%|███▏      | 15.7M/49.0M [00:02<00:04, 7.69MB/s]\n",
      " 34%|███▍      | 16.8M/49.0M [00:02<00:04, 7.58MB/s]\n",
      " 36%|███▋      | 17.8M/49.0M [00:02<00:04, 7.72MB/s]\n",
      " 39%|███▊      | 18.9M/49.0M [00:02<00:03, 7.67MB/s]\n",
      " 41%|████      | 19.9M/49.0M [00:02<00:03, 7.80MB/s]\n",
      " 43%|████▎     | 21.0M/49.0M [00:02<00:03, 7.93MB/s]\n",
      " 45%|████▍     | 22.0M/49.0M [00:02<00:03, 8.02MB/s]\n",
      " 47%|████▋     | 23.1M/49.0M [00:03<00:03, 8.12MB/s]\n",
      " 49%|████▉     | 24.1M/49.0M [00:03<00:03, 7.75MB/s]\n",
      " 51%|█████▏    | 25.2M/49.0M [00:03<00:03, 7.58MB/s]\n",
      " 54%|█████▎    | 26.2M/49.0M [00:03<00:03, 7.56MB/s]\n",
      " 56%|█████▌    | 27.3M/49.0M [00:03<00:03, 6.00MB/s]\n",
      " 58%|█████▊    | 28.3M/49.0M [00:03<00:03, 6.24MB/s]\n",
      " 60%|█████▉    | 29.4M/49.0M [00:03<00:02, 6.55MB/s]\n",
      " 62%|██████▏   | 30.4M/49.0M [00:04<00:02, 6.75MB/s]\n",
      " 64%|██████▍   | 31.5M/49.0M [00:04<00:02, 7.03MB/s]\n",
      " 66%|██████▋   | 32.5M/49.0M [00:04<00:02, 7.36MB/s]\n",
      " 69%|██████▊   | 33.6M/49.0M [00:04<00:01, 7.72MB/s]\n",
      " 71%|███████   | 34.6M/49.0M [00:04<00:01, 7.76MB/s]\n",
      " 73%|███████▎  | 35.7M/49.0M [00:04<00:01, 7.58MB/s]\n",
      " 75%|███████▍  | 36.7M/49.0M [00:04<00:01, 7.95MB/s]\n",
      " 77%|███████▋  | 37.7M/49.0M [00:05<00:01, 8.08MB/s]\n",
      " 79%|███████▉  | 38.8M/49.0M [00:05<00:01, 7.92MB/s]\n",
      " 81%|████████▏ | 39.8M/49.0M [00:05<00:01, 7.83MB/s]\n",
      " 84%|████████▎ | 40.9M/49.0M [00:05<00:01, 8.01MB/s]\n",
      " 86%|████████▌ | 41.9M/49.0M [00:05<00:00, 7.51MB/s]\n",
      " 88%|████████▊ | 43.0M/49.0M [00:05<00:00, 7.64MB/s]\n",
      " 90%|████████▉ | 44.0M/49.0M [00:05<00:00, 7.99MB/s]\n",
      " 92%|█████████▏| 45.1M/49.0M [00:05<00:00, 8.04MB/s]\n",
      " 94%|█████████▍| 46.1M/49.0M [00:06<00:00, 7.76MB/s]\n",
      " 96%|█████████▋| 47.2M/49.0M [00:06<00:00, 7.53MB/s]\n",
      " 99%|█████████▊| 48.2M/49.0M [00:06<00:00, 6.96MB/s]\n",
      "100%|██████████| 49.0M/49.0M [00:06<00:00, 6.96MB/s]\n",
      "100%|██████████| 49.0M/49.0M [00:06<00:00, 7.47MB/s]\n",
      "2024/03/15 13:13:57 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logged at level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2024/03/15 13:13:59 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'VGG16Model' already exists. Creating a new version of this model...\n",
      "2024/03/15 13:14:38 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: VGG16Model, version 3\n",
      "Created version '3' of model 'VGG16Model'.\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-15 13:18:12,039: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]\n",
      "[2024-03-15 13:18:12,043: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 13:18:12,046: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 13:18:12,046: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 13:18:12,048: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2024-03-15 13:18:12,050: INFO: data_ingestion: Downloading data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 13:18:23,609: INFO: data_ingestion: Downloaded data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 13:18:24,761: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 13:18:24,761: INFO: main: *******************]\n",
      "[2024-03-15 13:18:24,762: INFO: main: >>>>>> stage Prepare base model started <<<<<<]\n",
      "[2024-03-15 13:18:24,765: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 13:18:24,768: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 13:18:24,770: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 13:18:24,772: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "[2024-03-15 13:18:25,585: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "[2024-03-15 13:18:26,977: INFO: main: >>>>>> stage Prepare base model completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 13:18:26,977: INFO: main: *******************]\n",
      "[2024-03-15 13:18:26,978: INFO: main: >>>>>> stage Training started <<<<<<]\n",
      "[2024-03-15 13:18:26,982: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 13:18:26,986: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 13:18:26,988: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 13:18:26,989: INFO: common: created directory at: artifacts\\training]\n",
      "Found 68 images belonging to 2 classes.\n",
      "Found 275 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\n",
      " 1/17 [>.............................] - ETA: 1:51 - loss: 0.6535 - accuracy: 0.5625\n",
      " 2/17 [==>...........................] - ETA: 1:22 - loss: 3.0727 - accuracy: 0.5938\n",
      " 3/17 [====>.........................] - ETA: 1:24 - loss: 8.4562 - accuracy: 0.5625\n",
      " 4/17 [======>.......................] - ETA: 1:21 - loss: 9.2850 - accuracy: 0.5781\n",
      " 5/17 [=======>......................] - ETA: 1:19 - loss: 10.6085 - accuracy: 0.5125\n",
      " 6/17 [=========>....................] - ETA: 1:17 - loss: 13.2509 - accuracy: 0.5417\n",
      " 7/17 [===========>..................] - ETA: 1:10 - loss: 13.7802 - accuracy: 0.5446\n",
      " 8/17 [=============>................] - ETA: 56s - loss: 13.7867 - accuracy: 0.5391 \n",
      " 9/17 [==============>...............] - ETA: 51s - loss: 16.4211 - accuracy: 0.5344\n",
      "10/17 [================>.............] - ETA: 44s - loss: 14.6565 - accuracy: 0.5782\n",
      "11/17 [==================>...........] - ETA: 38s - loss: 13.3484 - accuracy: 0.5767\n",
      "12/17 [====================>.........] - ETA: 32s - loss: 14.3770 - accuracy: 0.5642\n",
      "13/17 [=====================>........] - ETA: 25s - loss: 14.3881 - accuracy: 0.5590\n",
      "14/17 [=======================>......] - ETA: 19s - loss: 14.5361 - accuracy: 0.5592\n",
      "15/17 [=========================>....] - ETA: 13s - loss: 13.7674 - accuracy: 0.5771\n",
      "16/17 [===========================>..] - ETA: 6s - loss: 12.9516 - accuracy: 0.5679 \n",
      "17/17 [==============================] - ETA: 0s - loss: 14.1925 - accuracy: 0.5560\n",
      "17/17 [==============================] - 140s 8s/step - loss: 14.1925 - accuracy: 0.5560 - val_loss: 15.8035 - val_accuracy: 0.3906\n",
      "Epoch 2/10\n",
      "\n",
      " 1/17 [>.............................] - ETA: 2:01 - loss: 14.7896 - accuracy: 0.4375\n",
      " 2/17 [==>...........................] - ETA: 1:39 - loss: 18.2241 - accuracy: 0.4688\n",
      " 3/17 [====>.........................] - ETA: 1:31 - loss: 16.9394 - accuracy: 0.4167\n",
      " 4/17 [======>.......................] - ETA: 1:28 - loss: 21.2475 - accuracy: 0.4375\n",
      " 5/17 [=======>......................] - ETA: 1:19 - loss: 17.0715 - accuracy: 0.5125\n",
      " 6/17 [=========>....................] - ETA: 1:13 - loss: 15.7858 - accuracy: 0.5000\n",
      " 7/17 [===========>..................] - ETA: 1:06 - loss: 17.4747 - accuracy: 0.5000\n",
      " 8/17 [=============>................] - ETA: 58s - loss: 15.7309 - accuracy: 0.4922 \n",
      " 9/17 [==============>...............] - ETA: 52s - loss: 16.6566 - accuracy: 0.5000\n",
      "10/17 [================>.............] - ETA: 45s - loss: 15.0420 - accuracy: 0.5375\n",
      "11/17 [==================>...........] - ETA: 39s - loss: 14.0003 - accuracy: 0.5455\n",
      "12/17 [====================>.........] - ETA: 32s - loss: 13.6461 - accuracy: 0.5521\n",
      "13/17 [=====================>........] - ETA: 25s - loss: 13.0197 - accuracy: 0.5481\n",
      "14/17 [=======================>......] - ETA: 19s - loss: 14.6475 - accuracy: 0.5268\n",
      "15/17 [=========================>....] - ETA: 12s - loss: 15.2354 - accuracy: 0.5250\n",
      "16/17 [===========================>..] - ETA: 6s - loss: 15.0857 - accuracy: 0.5267 \n",
      "17/17 [==============================] - ETA: 0s - loss: 14.4858 - accuracy: 0.5405\n",
      "17/17 [==============================] - 131s 8s/step - loss: 14.4858 - accuracy: 0.5405 - val_loss: 0.1194 - val_accuracy: 0.9688\n",
      "Epoch 3/10\n",
      "\n",
      " 1/17 [>.............................] - ETA: 2:03 - loss: 0.3624 - accuracy: 0.8125\n",
      " 2/17 [==>...........................] - ETA: 1:35 - loss: 2.2269 - accuracy: 0.5625\n",
      " 3/17 [====>.........................] - ETA: 1:27 - loss: 14.8006 - accuracy: 0.5000\n",
      " 4/17 [======>.......................] - ETA: 1:20 - loss: 11.4162 - accuracy: 0.5781\n",
      " 5/17 [=======>......................] - ETA: 1:12 - loss: 9.1365 - accuracy: 0.6625 \n",
      " 6/17 [=========>....................] - ETA: 1:07 - loss: 7.7352 - accuracy: 0.6979\n",
      " 7/17 [===========>..................] - ETA: 1:00 - loss: 7.4913 - accuracy: 0.6429\n",
      " 8/17 [=============>................] - ETA: 55s - loss: 12.6591 - accuracy: 0.6016\n",
      " 9/17 [==============>...............] - ETA: 49s - loss: 11.3791 - accuracy: 0.6319\n",
      "10/17 [================>.............] - ETA: 42s - loss: 10.3840 - accuracy: 0.6500\n",
      "11/17 [==================>...........] - ETA: 37s - loss: 9.9225 - accuracy: 0.6477 \n",
      "12/17 [====================>.........] - ETA: 30s - loss: 10.0430 - accuracy: 0.6302\n",
      "13/17 [=====================>........] - ETA: 23s - loss: 9.8885 - accuracy: 0.6359 \n",
      "14/17 [=======================>......] - ETA: 17s - loss: 10.1858 - accuracy: 0.6351\n",
      "15/17 [=========================>....] - ETA: 11s - loss: 9.4996 - accuracy: 0.6476 \n",
      "16/17 [===========================>..] - ETA: 5s - loss: 8.9783 - accuracy: 0.6543 \n",
      "17/17 [==============================] - ETA: 0s - loss: 8.7268 - accuracy: 0.6448\n",
      "17/17 [==============================] - 127s 7s/step - loss: 8.7268 - accuracy: 0.6448 - val_loss: 10.8715 - val_accuracy: 0.6094\n",
      "Epoch 4/10\n",
      "\n",
      " 1/17 [>.............................] - ETA: 1:51 - loss: 11.2834 - accuracy: 0.6875\n",
      " 2/17 [==>...........................] - ETA: 1:27 - loss: 6.1385 - accuracy: 0.7500 \n",
      " 3/17 [====>.........................] - ETA: 1:22 - loss: 4.3253 - accuracy: 0.7708\n",
      " 4/17 [======>.......................] - ETA: 1:25 - loss: 3.6110 - accuracy: 0.7812\n",
      " 5/17 [=======>......................] - ETA: 1:19 - loss: 3.6423 - accuracy: 0.7250\n",
      " 6/17 [=========>....................] - ETA: 1:14 - loss: 5.5868 - accuracy: 0.6875\n",
      " 7/17 [===========>..................] - ETA: 1:07 - loss: 4.9865 - accuracy: 0.7054\n",
      " 8/17 [=============>................] - ETA: 1:01 - loss: 4.5374 - accuracy: 0.7188\n",
      " 9/17 [==============>...............] - ETA: 55s - loss: 4.0846 - accuracy: 0.7431 \n",
      "10/17 [================>.............] - ETA: 48s - loss: 3.8012 - accuracy: 0.7563\n",
      "11/17 [==================>...........] - ETA: 41s - loss: 4.1477 - accuracy: 0.7273\n",
      "12/17 [====================>.........] - ETA: 34s - loss: 5.8369 - accuracy: 0.7031\n",
      "13/17 [=====================>........] - ETA: 27s - loss: 5.8719 - accuracy: 0.6875\n",
      "14/17 [=======================>......] - ETA: 20s - loss: 6.3923 - accuracy: 0.6830\n",
      "15/17 [=========================>....] - ETA: 13s - loss: 6.0657 - accuracy: 0.7000\n",
      "16/17 [===========================>..] - ETA: 6s - loss: 5.7233 - accuracy: 0.7070 \n",
      "17/17 [==============================] - ETA: 0s - loss: 5.6570 - accuracy: 0.7104\n",
      "17/17 [==============================] - 140s 8s/step - loss: 5.6570 - accuracy: 0.7104 - val_loss: 0.0123 - val_accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "\n",
      " 1/17 [>.............................] - ETA: 1:48 - loss: 0.0856 - accuracy: 0.9375\n",
      " 2/17 [==>...........................] - ETA: 1:46 - loss: 0.9373 - accuracy: 0.8750\n",
      " 3/17 [====>.........................] - ETA: 1:36 - loss: 1.0256 - accuracy: 0.8750\n",
      " 4/17 [======>.......................] - ETA: 1:30 - loss: 0.8079 - accuracy: 0.8906\n",
      " 5/17 [=======>......................] - ETA: 1:22 - loss: 0.9941 - accuracy: 0.8750\n",
      " 6/17 [=========>....................] - ETA: 1:16 - loss: 1.0969 - accuracy: 0.8750\n",
      " 7/17 [===========>..................] - ETA: 1:09 - loss: 1.0483 - accuracy: 0.8661\n",
      " 8/17 [=============>................] - ETA: 1:03 - loss: 0.9173 - accuracy: 0.8828\n",
      " 9/17 [==============>...............] - ETA: 56s - loss: 0.9108 - accuracy: 0.8681 \n",
      "10/17 [================>.............] - ETA: 48s - loss: 0.9982 - accuracy: 0.8500\n",
      "11/17 [==================>...........] - ETA: 41s - loss: 1.6008 - accuracy: 0.8239\n",
      "12/17 [====================>.........] - ETA: 34s - loss: 2.0219 - accuracy: 0.7969\n",
      "13/17 [=====================>........] - ETA: 27s - loss: 3.1617 - accuracy: 0.7500\n",
      "14/17 [=======================>......] - ETA: 20s - loss: 3.9432 - accuracy: 0.7500\n",
      "15/17 [=========================>....] - ETA: 13s - loss: 4.9705 - accuracy: 0.7208\n",
      "16/17 [===========================>..] - ETA: 6s - loss: 5.2683 - accuracy: 0.7227 \n",
      "17/17 [==============================] - ETA: 0s - loss: 5.2073 - accuracy: 0.7259\n",
      "17/17 [==============================] - 134s 8s/step - loss: 5.2073 - accuracy: 0.7259 - val_loss: 1.7652 - val_accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "\n",
      " 1/17 [>.............................] - ETA: 1:55 - loss: 2.0200 - accuracy: 0.6250\n",
      " 2/17 [==>...........................] - ETA: 1:26 - loss: 1.0584 - accuracy: 0.7812\n",
      " 3/17 [====>.........................] - ETA: 1:25 - loss: 2.2349 - accuracy: 0.7917\n",
      " 4/17 [======>.......................] - ETA: 1:22 - loss: 1.7366 - accuracy: 0.8281\n",
      " 5/17 [=======>......................] - ETA: 1:00 - loss: 1.6949 - accuracy: 0.8209\n",
      " 6/17 [=========>....................] - ETA: 58s - loss: 2.8015 - accuracy: 0.7952 \n",
      " 7/17 [===========>..................] - ETA: 55s - loss: 2.3977 - accuracy: 0.8182\n",
      " 8/17 [=============>................] - ETA: 49s - loss: 2.0874 - accuracy: 0.8261\n",
      " 9/17 [==============>...............] - ETA: 45s - loss: 1.8325 - accuracy: 0.8473\n",
      "10/17 [================>.............] - ETA: 40s - loss: 1.6410 - accuracy: 0.8571\n",
      "11/17 [==================>...........] - ETA: 35s - loss: 1.4877 - accuracy: 0.8650\n",
      "12/17 [====================>.........] - ETA: 29s - loss: 1.5172 - accuracy: 0.8492\n",
      "13/17 [=====================>........] - ETA: 23s - loss: 1.5179 - accuracy: 0.8410\n",
      "14/17 [=======================>......] - ETA: 17s - loss: 1.7179 - accuracy: 0.8341\n",
      "15/17 [=========================>....] - ETA: 11s - loss: 1.7676 - accuracy: 0.8326\n",
      "16/17 [===========================>..] - ETA: 5s - loss: 1.9065 - accuracy: 0.8230 \n",
      "17/17 [==============================] - ETA: 0s - loss: 2.2659 - accuracy: 0.8108\n",
      "17/17 [==============================] - 127s 7s/step - loss: 2.2659 - accuracy: 0.8108 - val_loss: 2.1799 - val_accuracy: 0.6875\n",
      "Epoch 7/10\n",
      "\n",
      " 1/17 [>.............................] - ETA: 1:47 - loss: 4.3245 - accuracy: 0.6875\n",
      " 2/17 [==>...........................] - ETA: 1:27 - loss: 3.5233 - accuracy: 0.7500\n",
      " 3/17 [====>.........................] - ETA: 1:26 - loss: 2.4465 - accuracy: 0.7917\n",
      " 4/17 [======>.......................] - ETA: 1:21 - loss: 1.9018 - accuracy: 0.8281\n",
      " 5/17 [=======>......................] - ETA: 1:13 - loss: 1.7666 - accuracy: 0.8375\n",
      " 6/17 [=========>....................] - ETA: 1:10 - loss: 1.7131 - accuracy: 0.8438\n",
      " 7/17 [===========>..................] - ETA: 1:04 - loss: 1.7356 - accuracy: 0.8393\n",
      " 8/17 [=============>................] - ETA: 58s - loss: 1.9628 - accuracy: 0.8203 \n",
      " 9/17 [==============>...............] - ETA: 52s - loss: 2.6610 - accuracy: 0.7708\n",
      "10/17 [================>.............] - ETA: 45s - loss: 3.8082 - accuracy: 0.7625\n",
      "11/17 [==================>...........] - ETA: 39s - loss: 3.6602 - accuracy: 0.7670\n",
      "12/17 [====================>.........] - ETA: 32s - loss: 3.4917 - accuracy: 0.7708\n",
      "13/17 [=====================>........] - ETA: 24s - loss: 3.4683 - accuracy: 0.7692\n",
      "14/17 [=======================>......] - ETA: 18s - loss: 4.6147 - accuracy: 0.7488\n",
      "15/17 [=========================>....] - ETA: 12s - loss: 4.3862 - accuracy: 0.7489\n",
      "16/17 [===========================>..] - ETA: 6s - loss: 4.1025 - accuracy: 0.7613 \n",
      "17/17 [==============================] - ETA: 0s - loss: 3.8494 - accuracy: 0.7761\n",
      "17/17 [==============================] - 133s 8s/step - loss: 3.8494 - accuracy: 0.7761 - val_loss: 0.0380 - val_accuracy: 0.9844\n",
      "Epoch 8/10\n",
      "\n",
      " 1/17 [>.............................] - ETA: 2:30 - loss: 0.2275 - accuracy: 0.8750\n",
      " 2/17 [==>...........................] - ETA: 1:44 - loss: 0.8765 - accuracy: 0.8438\n",
      " 3/17 [====>.........................] - ETA: 1:33 - loss: 1.4027 - accuracy: 0.8333\n",
      " 4/17 [======>.......................] - ETA: 1:28 - loss: 1.3581 - accuracy: 0.8594\n",
      " 5/17 [=======>......................] - ETA: 1:20 - loss: 1.1065 - accuracy: 0.8750\n",
      " 6/17 [=========>....................] - ETA: 1:13 - loss: 1.2429 - accuracy: 0.8646\n",
      " 7/17 [===========>..................] - ETA: 1:07 - loss: 1.0658 - accuracy: 0.8839\n",
      " 8/17 [=============>................] - ETA: 59s - loss: 1.0344 - accuracy: 0.8906 \n",
      " 9/17 [==============>...............] - ETA: 52s - loss: 0.9381 - accuracy: 0.8958\n",
      "10/17 [================>.............] - ETA: 46s - loss: 0.9383 - accuracy: 0.8938\n",
      "11/17 [==================>...........] - ETA: 39s - loss: 1.0401 - accuracy: 0.8807\n",
      "12/17 [====================>.........] - ETA: 32s - loss: 1.2588 - accuracy: 0.8646\n",
      "13/17 [=====================>........] - ETA: 26s - loss: 1.5556 - accuracy: 0.8510\n",
      "14/17 [=======================>......] - ETA: 19s - loss: 1.4805 - accuracy: 0.8571\n",
      "15/17 [=========================>....] - ETA: 12s - loss: 1.4109 - accuracy: 0.8583\n",
      "16/17 [===========================>..] - ETA: 6s - loss: 1.3455 - accuracy: 0.8633 \n",
      "17/17 [==============================] - ETA: 0s - loss: 1.3299 - accuracy: 0.8649\n",
      "17/17 [==============================] - 132s 8s/step - loss: 1.3299 - accuracy: 0.8649 - val_loss: 0.0443 - val_accuracy: 0.9844\n",
      "Epoch 9/10\n",
      "\n",
      " 1/17 [>.............................] - ETA: 1:44 - loss: 0.0206 - accuracy: 1.0000\n",
      " 2/17 [==>...........................] - ETA: 1:41 - loss: 0.2816 - accuracy: 0.9375\n",
      " 3/17 [====>.........................] - ETA: 1:29 - loss: 0.7610 - accuracy: 0.8750\n",
      " 4/17 [======>.......................] - ETA: 1:21 - loss: 0.9414 - accuracy: 0.8281\n",
      " 5/17 [=======>......................] - ETA: 1:00 - loss: 1.3638 - accuracy: 0.8060\n",
      " 6/17 [=========>....................] - ETA: 58s - loss: 6.7744 - accuracy: 0.7470 \n",
      " 7/17 [===========>..................] - ETA: 54s - loss: 5.6795 - accuracy: 0.7879\n",
      " 8/17 [=============>................] - ETA: 50s - loss: 5.0987 - accuracy: 0.8000\n",
      " 9/17 [==============>...............] - ETA: 45s - loss: 5.1914 - accuracy: 0.7710\n",
      "10/17 [================>.............] - ETA: 40s - loss: 6.5310 - accuracy: 0.7347\n",
      "11/17 [==================>...........] - ETA: 35s - loss: 6.9083 - accuracy: 0.7117\n",
      "12/17 [====================>.........] - ETA: 29s - loss: 7.2054 - accuracy: 0.6927\n",
      "13/17 [=====================>........] - ETA: 23s - loss: 7.4858 - accuracy: 0.6667\n",
      "14/17 [=======================>......] - ETA: 17s - loss: 8.2105 - accuracy: 0.6493\n",
      "15/17 [=========================>....] - ETA: 11s - loss: 7.8718 - accuracy: 0.6520\n",
      "16/17 [===========================>..] - ETA: 5s - loss: 7.3767 - accuracy: 0.6626 \n",
      "17/17 [==============================] - ETA: 0s - loss: 6.9215 - accuracy: 0.6834\n",
      "17/17 [==============================] - 130s 8s/step - loss: 6.9215 - accuracy: 0.6834 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "\n",
      " 1/17 [>.............................] - ETA: 2:10 - loss: 0.4370 - accuracy: 0.9375\n",
      " 2/17 [==>...........................] - ETA: 1:56 - loss: 0.4203 - accuracy: 0.9375\n",
      " 3/17 [====>.........................] - ETA: 1:43 - loss: 0.7652 - accuracy: 0.9167\n",
      " 4/17 [======>.......................] - ETA: 1:37 - loss: 1.1336 - accuracy: 0.8750\n",
      " 5/17 [=======>......................] - ETA: 1:27 - loss: 1.2737 - accuracy: 0.8375\n",
      " 6/17 [=========>....................] - ETA: 1:20 - loss: 1.3478 - accuracy: 0.8333\n",
      " 7/17 [===========>..................] - ETA: 1:12 - loss: 1.3753 - accuracy: 0.8482\n",
      " 8/17 [=============>................] - ETA: 1:03 - loss: 1.4326 - accuracy: 0.8438\n",
      " 9/17 [==============>...............] - ETA: 55s - loss: 1.5413 - accuracy: 0.8542 \n",
      "10/17 [================>.............] - ETA: 47s - loss: 1.4599 - accuracy: 0.8562\n",
      "11/17 [==================>...........] - ETA: 40s - loss: 1.4161 - accuracy: 0.8523\n",
      "12/17 [====================>.........] - ETA: 33s - loss: 1.3933 - accuracy: 0.8542\n",
      "13/17 [=====================>........] - ETA: 26s - loss: 1.3201 - accuracy: 0.8558\n",
      "14/17 [=======================>......] - ETA: 20s - loss: 1.3216 - accuracy: 0.8527\n",
      "15/17 [=========================>....] - ETA: 13s - loss: 1.3654 - accuracy: 0.8500\n",
      "16/17 [===========================>..] - ETA: 6s - loss: 1.4086 - accuracy: 0.8438 \n",
      "17/17 [==============================] - ETA: 0s - loss: 1.4573 - accuracy: 0.8419\n",
      "17/17 [==============================] - 138s 8s/step - loss: 1.4573 - accuracy: 0.8419 - val_loss: 0.0281 - val_accuracy: 0.9844\n",
      "[2024-03-15 13:40:41,987: INFO: main: >>>>>> stage Training completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 13:40:41,988: INFO: main: *******************]\n",
      "[2024-03-15 13:40:41,988: INFO: main: >>>>>> stage Evaluation stage started <<<<<<]\n",
      "[2024-03-15 13:40:41,996: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 13:40:42,000: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 13:40:42,002: INFO: common: created directory at: artifacts]\n",
      "Found 102 images belonging to 2 classes.\n",
      "\n",
      "1/7 [===>..........................] - ETA: 38s - loss: 0.1125 - accuracy: 0.9375\n",
      "2/7 [=======>......................] - ETA: 34s - loss: 0.0562 - accuracy: 0.9688\n",
      "3/7 [===========>..................] - ETA: 27s - loss: 0.0388 - accuracy: 0.9792\n",
      "4/7 [================>.............] - ETA: 19s - loss: 0.0291 - accuracy: 0.9844\n",
      "5/7 [====================>.........] - ETA: 13s - loss: 0.0233 - accuracy: 0.9875\n",
      "6/7 [========================>.....] - ETA: 6s - loss: 0.0194 - accuracy: 0.9896 \n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9902\n",
      "7/7 [==============================] - 41s 6s/step - loss: 0.0183 - accuracy: 0.9902\n",
      "[2024-03-15 13:41:23,994: INFO: common: json file saved at: scores.json]\n",
      "[2024-03-15 13:41:23,996: INFO: common: json file saved at: scores.json]\n",
      "[2024-03-15 13:41:31,037: WARNING: save: Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.]\n",
      "[2024-03-15 13:41:33,323: INFO: builder_impl: Assets written to: C:\\Users\\mayan\\AppData\\Local\\Temp\\tmpiabuhex2\\model\\data\\model\\assets]\n",
      "[2024-03-15 13:42:09,646: INFO: main: >>>>>> stage Evaluation stage completed <<<<<<\n",
      "\n",
      "x==========x]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?/export=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ\n",
      "From (redirected): https://drive.google.com/uc?%2Fexport=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ&confirm=t&uuid=09da8487-eb99-4bef-a1d4-16c7dc3cf7d2\n",
      "To: d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\artifacts\\data_ingestion\\data.zip\n",
      "\n",
      "  0%|          | 0.00/49.0M [00:00<?, ?B/s]\n",
      "  1%|          | 524k/49.0M [00:00<00:11, 4.26MB/s]\n",
      "  2%|▏         | 1.05M/49.0M [00:00<00:10, 4.50MB/s]\n",
      "  4%|▍         | 2.10M/49.0M [00:00<00:08, 5.60MB/s]\n",
      "  6%|▋         | 3.15M/49.0M [00:01<00:19, 2.33MB/s]\n",
      "  7%|▋         | 3.67M/49.0M [00:01<00:17, 2.53MB/s]\n",
      "  9%|▊         | 4.19M/49.0M [00:01<00:15, 2.83MB/s]\n",
      " 10%|▉         | 4.72M/49.0M [00:01<00:14, 3.10MB/s]\n",
      " 11%|█         | 5.24M/49.0M [00:01<00:13, 3.32MB/s]\n",
      " 12%|█▏        | 5.77M/49.0M [00:01<00:12, 3.51MB/s]\n",
      " 13%|█▎        | 6.29M/49.0M [00:01<00:11, 3.68MB/s]\n",
      " 14%|█▍        | 6.82M/49.0M [00:02<00:11, 3.79MB/s]\n",
      " 15%|█▍        | 7.34M/49.0M [00:02<00:10, 3.88MB/s]\n",
      " 16%|█▌        | 7.86M/49.0M [00:02<00:10, 3.80MB/s]\n",
      " 17%|█▋        | 8.39M/49.0M [00:02<00:09, 4.12MB/s]\n",
      " 18%|█▊        | 8.91M/49.0M [00:02<00:09, 4.40MB/s]\n",
      " 20%|██        | 9.96M/49.0M [00:02<00:07, 5.16MB/s]\n",
      " 22%|██▏       | 11.0M/49.0M [00:02<00:06, 5.70MB/s]\n",
      " 25%|██▍       | 12.1M/49.0M [00:02<00:05, 6.26MB/s]\n",
      " 27%|██▋       | 13.1M/49.0M [00:03<00:05, 6.78MB/s]\n",
      " 29%|██▉       | 14.2M/49.0M [00:03<00:04, 7.08MB/s]\n",
      " 31%|███       | 15.2M/49.0M [00:03<00:04, 7.28MB/s]\n",
      " 33%|███▎      | 16.3M/49.0M [00:03<00:04, 7.68MB/s]\n",
      " 35%|███▌      | 17.3M/49.0M [00:03<00:04, 7.88MB/s]\n",
      " 37%|███▋      | 18.4M/49.0M [00:03<00:03, 7.94MB/s]\n",
      " 40%|███▉      | 19.4M/49.0M [00:03<00:03, 7.67MB/s]\n",
      " 42%|████▏     | 20.4M/49.0M [00:04<00:03, 7.99MB/s]\n",
      " 44%|████▍     | 21.5M/49.0M [00:04<00:03, 8.05MB/s]\n",
      " 46%|████▌     | 22.5M/49.0M [00:04<00:03, 7.98MB/s]\n",
      " 48%|████▊     | 23.6M/49.0M [00:04<00:03, 8.08MB/s]\n",
      " 50%|█████     | 24.6M/49.0M [00:04<00:02, 8.14MB/s]\n",
      " 52%|█████▏    | 25.7M/49.0M [00:04<00:02, 8.27MB/s]\n",
      " 55%|█████▍    | 26.7M/49.0M [00:04<00:02, 8.18MB/s]\n",
      " 57%|█████▋    | 27.8M/49.0M [00:04<00:02, 8.34MB/s]\n",
      " 59%|█████▉    | 28.8M/49.0M [00:05<00:02, 8.57MB/s]\n",
      " 61%|██████    | 29.9M/49.0M [00:05<00:02, 8.67MB/s]\n",
      " 63%|██████▎   | 30.9M/49.0M [00:05<00:02, 6.35MB/s]\n",
      " 65%|██████▌   | 32.0M/49.0M [00:05<00:02, 6.75MB/s]\n",
      " 67%|██████▋   | 33.0M/49.0M [00:05<00:02, 6.79MB/s]\n",
      " 70%|██████▉   | 34.1M/49.0M [00:05<00:02, 6.13MB/s]\n",
      " 72%|███████▏  | 35.1M/49.0M [00:06<00:04, 3.22MB/s]\n",
      " 75%|███████▍  | 36.7M/49.0M [00:06<00:02, 4.13MB/s]\n",
      " 77%|███████▋  | 37.7M/49.0M [00:06<00:02, 4.82MB/s]\n",
      " 79%|███████▉  | 38.8M/49.0M [00:07<00:01, 5.43MB/s]\n",
      " 81%|████████▏ | 39.8M/49.0M [00:07<00:01, 6.12MB/s]\n",
      " 84%|████████▎ | 40.9M/49.0M [00:07<00:01, 6.59MB/s]\n",
      " 86%|████████▌ | 41.9M/49.0M [00:07<00:00, 7.09MB/s]\n",
      " 88%|████████▊ | 43.0M/49.0M [00:07<00:00, 7.45MB/s]\n",
      " 90%|████████▉ | 44.0M/49.0M [00:07<00:00, 7.85MB/s]\n",
      " 92%|█████████▏| 45.1M/49.0M [00:07<00:00, 8.06MB/s]\n",
      " 94%|█████████▍| 46.1M/49.0M [00:07<00:00, 8.35MB/s]\n",
      " 97%|█████████▋| 47.7M/49.0M [00:08<00:00, 9.25MB/s]\n",
      "100%|█████████▉| 48.8M/49.0M [00:08<00:00, 9.14MB/s]\n",
      "100%|██████████| 49.0M/49.0M [00:08<00:00, 5.99MB/s]\n",
      "2024/03/15 13:41:24 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logged at level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2024/03/15 13:41:26 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'VGG16Model' already exists. Creating a new version of this model...\n",
      "2024/03/15 13:42:09 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: VGG16Model, version 4\n",
      "Created version '4' of model 'VGG16Model'.\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-15 14:39:02,570: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]\n",
      "[2024-03-15 14:39:02,575: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 14:39:02,577: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 14:39:02,578: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 14:39:02,578: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2024-03-15 14:39:02,580: INFO: data_ingestion: Downloading data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 14:39:13,220: INFO: data_ingestion: Downloaded data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 14:39:14,474: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 14:39:14,475: INFO: main: *******************]\n",
      "[2024-03-15 14:39:14,475: INFO: main: >>>>>> stage Prepare base model started <<<<<<]\n",
      "[2024-03-15 14:39:14,481: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 14:39:14,483: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 14:39:14,484: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 14:39:14,485: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "[2024-03-15 14:39:15,486: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 100356    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,815,044\n",
      "Trainable params: 100,356\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "[2024-03-15 14:39:17,206: INFO: main: >>>>>> stage Prepare base model completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 14:39:17,207: INFO: main: *******************]\n",
      "[2024-03-15 14:39:17,207: INFO: main: >>>>>> stage Training started <<<<<<]\n",
      "[2024-03-15 14:39:17,212: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 14:39:17,215: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 14:39:17,216: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 14:39:17,217: INFO: common: created directory at: artifacts\\training]\n",
      "Found 68 images belonging to 2 classes.\n",
      "Found 275 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "[2024-03-15 14:39:31,275: ERROR: main: Graph execution error:\n",
      "\n",
      "Detected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n",
      "    File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 43, in <module>\n",
      "      model_trainer.main()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_03_model_trainer.py\", line 22, in main\n",
      "      training.train()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\model_trainer.py\", line 75, in train\n",
      "      self.model.fit(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n",
      "      loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n",
      "      return self.compiled_loss(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n",
      "      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n",
      "      losses = call_fn(y_true, y_pred)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n",
      "      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n",
      "      return backend.categorical_crossentropy(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\backend.py\", line 5565, in categorical_crossentropy\n",
      "      return tf.nn.softmax_cross_entropy_with_logits(\n",
      "Node: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\n",
      "logits and labels must be broadcastable: logits_size=[16,4] labels_size=[16,2]\n",
      "\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_1463]]\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 43, in <module>\n",
      "    model_trainer.main()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_03_model_trainer.py\", line 22, in main\n",
      "    training.train()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\model_trainer.py\", line 75, in train\n",
      "    self.model.fit(\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n",
      "    File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 43, in <module>\n",
      "      model_trainer.main()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_03_model_trainer.py\", line 22, in main\n",
      "      training.train()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\model_trainer.py\", line 75, in train\n",
      "      self.model.fit(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n",
      "      loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n",
      "      return self.compiled_loss(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n",
      "      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n",
      "      losses = call_fn(y_true, y_pred)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n",
      "      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n",
      "      return backend.categorical_crossentropy(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\backend.py\", line 5565, in categorical_crossentropy\n",
      "      return tf.nn.softmax_cross_entropy_with_logits(\n",
      "Node: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\n",
      "logits and labels must be broadcastable: logits_size=[16,4] labels_size=[16,2]\n",
      "\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_1463]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?/export=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ\n",
      "From (redirected): https://drive.google.com/uc?%2Fexport=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ&confirm=t&uuid=a55074f2-e439-4a70-a839-d216094f7593\n",
      "To: d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\artifacts\\data_ingestion\\data.zip\n",
      "\n",
      "  0%|          | 0.00/49.0M [00:00<?, ?B/s]\n",
      "  1%|          | 524k/49.0M [00:00<00:11, 4.37MB/s]\n",
      "  3%|▎         | 1.57M/49.0M [00:00<00:08, 5.75MB/s]\n",
      "  5%|▌         | 2.62M/49.0M [00:00<00:07, 6.15MB/s]\n",
      "  7%|▋         | 3.67M/49.0M [00:00<00:06, 6.69MB/s]\n",
      " 10%|▉         | 4.72M/49.0M [00:00<00:08, 5.53MB/s]\n",
      " 12%|█▏        | 5.77M/49.0M [00:01<00:07, 5.44MB/s]\n",
      " 14%|█▍        | 6.82M/49.0M [00:01<00:07, 5.52MB/s]\n",
      " 16%|█▌        | 7.86M/49.0M [00:01<00:07, 5.74MB/s]\n",
      " 18%|█▊        | 8.91M/49.0M [00:01<00:06, 6.19MB/s]\n",
      " 20%|██        | 9.96M/49.0M [00:01<00:06, 6.29MB/s]\n",
      " 22%|██▏       | 11.0M/49.0M [00:01<00:05, 6.76MB/s]\n",
      " 25%|██▍       | 12.1M/49.0M [00:01<00:05, 7.10MB/s]\n",
      " 27%|██▋       | 13.1M/49.0M [00:02<00:05, 6.21MB/s]\n",
      " 29%|██▉       | 14.2M/49.0M [00:02<00:05, 6.82MB/s]\n",
      " 31%|███       | 15.2M/49.0M [00:02<00:04, 7.05MB/s]\n",
      " 33%|███▎      | 16.3M/49.0M [00:02<00:04, 6.87MB/s]\n",
      " 35%|███▌      | 17.3M/49.0M [00:02<00:04, 7.22MB/s]\n",
      " 37%|███▋      | 18.4M/49.0M [00:02<00:04, 7.36MB/s]\n",
      " 40%|███▉      | 19.4M/49.0M [00:02<00:03, 7.53MB/s]\n",
      " 42%|████▏     | 20.4M/49.0M [00:03<00:03, 7.86MB/s]\n",
      " 44%|████▍     | 21.5M/49.0M [00:03<00:03, 7.34MB/s]\n",
      " 46%|████▌     | 22.5M/49.0M [00:03<00:04, 5.86MB/s]\n",
      " 48%|████▊     | 23.6M/49.0M [00:03<00:04, 6.02MB/s]\n",
      " 50%|█████     | 24.6M/49.0M [00:03<00:03, 6.31MB/s]\n",
      " 52%|█████▏    | 25.7M/49.0M [00:03<00:03, 6.61MB/s]\n",
      " 55%|█████▍    | 26.7M/49.0M [00:04<00:03, 6.76MB/s]\n",
      " 57%|█████▋    | 27.8M/49.0M [00:04<00:03, 6.85MB/s]\n",
      " 59%|█████▉    | 28.8M/49.0M [00:04<00:02, 6.97MB/s]\n",
      " 61%|██████    | 29.9M/49.0M [00:04<00:02, 6.90MB/s]\n",
      " 63%|██████▎   | 30.9M/49.0M [00:04<00:02, 6.92MB/s]\n",
      " 65%|██████▌   | 32.0M/49.0M [00:04<00:02, 6.90MB/s]\n",
      " 67%|██████▋   | 33.0M/49.0M [00:05<00:02, 6.77MB/s]\n",
      " 70%|██████▉   | 34.1M/49.0M [00:05<00:02, 6.89MB/s]\n",
      " 72%|███████▏  | 35.1M/49.0M [00:05<00:02, 6.87MB/s]\n",
      " 74%|███████▍  | 36.2M/49.0M [00:05<00:01, 6.93MB/s]\n",
      " 76%|███████▌  | 37.2M/49.0M [00:05<00:01, 6.92MB/s]\n",
      " 78%|███████▊  | 38.3M/49.0M [00:05<00:01, 6.90MB/s]\n",
      " 80%|████████  | 39.3M/49.0M [00:05<00:01, 6.79MB/s]\n",
      " 82%|████████▏ | 40.4M/49.0M [00:06<00:01, 6.88MB/s]\n",
      " 85%|████████▍ | 41.4M/49.0M [00:06<00:01, 6.79MB/s]\n",
      " 87%|████████▋ | 42.5M/49.0M [00:06<00:00, 6.92MB/s]\n",
      " 89%|████████▉ | 43.5M/49.0M [00:06<00:00, 6.93MB/s]\n",
      " 91%|█████████ | 44.6M/49.0M [00:06<00:00, 7.05MB/s]\n",
      " 93%|█████████▎| 45.6M/49.0M [00:06<00:00, 6.96MB/s]\n",
      " 95%|█████████▌| 46.7M/49.0M [00:06<00:00, 6.96MB/s]\n",
      " 97%|█████████▋| 47.7M/49.0M [00:07<00:00, 6.95MB/s]\n",
      "100%|█████████▉| 48.8M/49.0M [00:07<00:00, 6.68MB/s]\n",
      "100%|██████████| 49.0M/49.0M [00:07<00:00, 6.67MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 47, in <module>\n",
      "    raise e\n",
      "  File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 43, in <module>\n",
      "    model_trainer.main()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_03_model_trainer.py\", line 22, in main\n",
      "    training.train()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\model_trainer.py\", line 75, in train\n",
      "    self.model.fit(\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n",
      "    File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 43, in <module>\n",
      "      model_trainer.main()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_03_model_trainer.py\", line 22, in main\n",
      "      training.train()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\model_trainer.py\", line 75, in train\n",
      "      self.model.fit(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n",
      "      loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n",
      "      return self.compiled_loss(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n",
      "      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n",
      "      losses = call_fn(y_true, y_pred)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n",
      "      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n",
      "      return backend.categorical_crossentropy(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\backend.py\", line 5565, in categorical_crossentropy\n",
      "      return tf.nn.softmax_cross_entropy_with_logits(\n",
      "Node: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\n",
      "logits and labels must be broadcastable: logits_size=[16,4] labels_size=[16,2]\n",
      "\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_1463]\n",
      "2024-03-15 14:39:31.445997: W tensorflow/core/kernels/data/generator_dataset_op.cc:108] Error occurred when finalizing GeneratorDataset iterator: FAILED_PRECONDITION: Python interpreter state is not initialized. The process may be terminated.\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-15 14:47:46,816: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?/export=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ\n",
      "From (redirected): https://drive.google.com/uc?%2Fexport=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ&confirm=t&uuid=05390b04-f5bf-47e6-a4f9-63a1eadd04ef\n",
      "To: d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\artifacts\\data_ingestion\\data.zip\n",
      "\n",
      "  0%|          | 0.00/49.0M [00:00<?, ?B/s]\n",
      "  2%|▏         | 1.05M/49.0M [00:00<00:06, 6.88MB/s]\n",
      "  4%|▍         | 2.10M/49.0M [00:00<00:05, 8.27MB/s]\n",
      "  6%|▋         | 3.15M/49.0M [00:00<00:05, 8.22MB/s]\n",
      "  9%|▊         | 4.19M/49.0M [00:00<00:05, 8.11MB/s]\n",
      " 11%|█         | 5.24M/49.0M [00:00<00:05, 8.00MB/s]\n",
      " 13%|█▎        | 6.29M/49.0M [00:00<00:05, 7.46MB/s]\n",
      " 15%|█▍        | 7.34M/49.0M [00:00<00:05, 7.91MB/s]\n",
      " 17%|█▋        | 8.39M/49.0M [00:01<00:05, 7.35MB/s]\n",
      " 19%|█▉        | 9.44M/49.0M [00:01<00:05, 6.87MB/s]\n",
      " 21%|██▏       | 10.5M/49.0M [00:01<00:05, 6.75MB/s]\n",
      " 24%|██▎       | 11.5M/49.0M [00:01<00:05, 7.09MB/s]\n",
      " 26%|██▌       | 12.6M/49.0M [00:01<00:04, 7.37MB/s]\n",
      " 28%|██▊       | 13.6M/49.0M [00:01<00:04, 7.60MB/s]\n",
      " 30%|██▉       | 14.7M/49.0M [00:01<00:04, 7.64MB/s]\n",
      " 32%|███▏      | 15.7M/49.0M [00:02<00:04, 7.57MB/s]\n",
      " 34%|███▍      | 16.8M/49.0M [00:02<00:04, 7.49MB/s]\n",
      " 36%|███▋      | 17.8M/49.0M [00:02<00:04, 7.44MB/s]\n",
      " 39%|███▊      | 18.9M/49.0M [00:02<00:03, 7.75MB/s]\n",
      " 41%|████      | 19.9M/49.0M [00:02<00:03, 7.83MB/s]\n",
      " 43%|████▎     | 21.0M/49.0M [00:02<00:03, 7.90MB/s]\n",
      " 45%|████▍     | 22.0M/49.0M [00:02<00:03, 7.80MB/s]\n",
      " 47%|████▋     | 23.1M/49.0M [00:03<00:03, 7.89MB/s]\n",
      " 49%|████▉     | 24.1M/49.0M [00:03<00:03, 7.79MB/s]\n",
      " 51%|█████▏    | 25.2M/49.0M [00:03<00:03, 7.63MB/s]\n",
      " 54%|█████▎    | 26.2M/49.0M [00:03<00:02, 7.92MB/s]\n",
      " 56%|█████▌    | 27.3M/49.0M [00:03<00:02, 7.86MB/s]\n",
      " 58%|█████▊    | 28.3M/49.0M [00:03<00:02, 8.00MB/s]\n",
      " 60%|█████▉    | 29.4M/49.0M [00:03<00:02, 7.96MB/s]\n",
      " 62%|██████▏   | 30.4M/49.0M [00:03<00:02, 8.32MB/s]\n",
      " 64%|██████▍   | 31.5M/49.0M [00:04<00:02, 8.49MB/s]\n",
      " 66%|██████▋   | 32.5M/49.0M [00:04<00:01, 8.79MB/s]\n",
      " 69%|██████▊   | 33.6M/49.0M [00:04<00:01, 9.15MB/s]\n",
      " 71%|███████   | 34.6M/49.0M [00:04<00:01, 8.95MB/s]\n",
      " 73%|███████▎  | 35.7M/49.0M [00:04<00:01, 9.30MB/s]\n",
      " 75%|███████▍  | 36.7M/49.0M [00:04<00:01, 9.32MB/s]\n",
      " 77%|███████▋  | 37.7M/49.0M [00:04<00:01, 8.96MB/s]\n",
      " 79%|███████▉  | 38.8M/49.0M [00:04<00:01, 8.89MB/s]\n",
      " 82%|████████▏ | 40.4M/49.0M [00:05<00:00, 9.34MB/s]\n",
      " 85%|████████▍ | 41.4M/49.0M [00:05<00:01, 7.08MB/s]\n",
      " 87%|████████▋ | 42.5M/49.0M [00:05<00:00, 7.49MB/s]\n",
      " 89%|████████▉ | 43.5M/49.0M [00:05<00:00, 7.82MB/s]\n",
      " 92%|█████████▏| 45.1M/49.0M [00:05<00:00, 8.46MB/s]\n",
      " 94%|█████████▍| 46.1M/49.0M [00:05<00:00, 8.31MB/s]\n",
      " 96%|█████████▋| 47.2M/49.0M [00:05<00:00, 8.12MB/s]\n",
      " 99%|█████████▊| 48.2M/49.0M [00:06<00:00, 8.20MB/s]\n",
      "100%|██████████| 49.0M/49.0M [00:06<00:00, 7.95MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 47, in <module>\n",
      "    raise e\n",
      "  File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 43, in <module>\n",
      "    model_trainer.main()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_03_model_trainer.py\", line 22, in main\n",
      "    training.train()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\model_trainer.py\", line 75, in train\n",
      "    self.model.fit(\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n",
      "    File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 43, in <module>\n",
      "      model_trainer.main()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_03_model_trainer.py\", line 22, in main\n",
      "      training.train()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\model_trainer.py\", line 75, in train\n",
      "      self.model.fit(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n",
      "      loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n",
      "      return self.compiled_loss(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n",
      "      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n",
      "      losses = call_fn(y_true, y_pred)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n",
      "      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n",
      "      return backend.categorical_crossentropy(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\backend.py\", line 5565, in categorical_crossentropy\n",
      "      return tf.nn.softmax_cross_entropy_with_logits(\n",
      "Node: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\n",
      "logits and labels must be broadcastable: logits_size=[16,4] labels_size=[16,2]\n",
      "\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_1463]\n",
      "2024-03-15 14:48:23.887549: W tensorflow/core/kernels/data/generator_dataset_op.cc:108] Error occurred when finalizing GeneratorDataset iterator: FAILED_PRECONDITION: Python interpreter state is not initialized. The process may be terminated.\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2024-03-15 14:47:46,818: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 14:47:46,826: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 14:47:46,830: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 14:47:46,833: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2024-03-15 14:47:46,836: INFO: data_ingestion: Downloading data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 14:47:57,355: INFO: data_ingestion: Downloaded data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 14:47:59,194: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 14:47:59,194: INFO: main: *******************]\n",
      "[2024-03-15 14:47:59,194: INFO: main: >>>>>> stage Prepare base model started <<<<<<]\n",
      "[2024-03-15 14:47:59,205: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 14:47:59,211: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 14:47:59,214: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 14:47:59,217: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "[2024-03-15 14:48:00,582: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 100356    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,815,044\n",
      "Trainable params: 100,356\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "[2024-03-15 14:48:02,160: INFO: main: >>>>>> stage Prepare base model completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 14:48:02,160: INFO: main: *******************]\n",
      "[2024-03-15 14:48:02,160: INFO: main: >>>>>> stage Training started <<<<<<]\n",
      "[2024-03-15 14:48:02,169: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 14:48:02,174: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 14:48:02,175: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 14:48:02,176: INFO: common: created directory at: artifacts\\training]\n",
      "Found 68 images belonging to 2 classes.\n",
      "Found 275 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "[2024-03-15 14:48:23,652: ERROR: main: Graph execution error:\n",
      "\n",
      "Detected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n",
      "    File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 43, in <module>\n",
      "      model_trainer.main()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_03_model_trainer.py\", line 22, in main\n",
      "      training.train()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\model_trainer.py\", line 75, in train\n",
      "      self.model.fit(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n",
      "      loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n",
      "      return self.compiled_loss(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n",
      "      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n",
      "      losses = call_fn(y_true, y_pred)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n",
      "      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n",
      "      return backend.categorical_crossentropy(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\backend.py\", line 5565, in categorical_crossentropy\n",
      "      return tf.nn.softmax_cross_entropy_with_logits(\n",
      "Node: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\n",
      "logits and labels must be broadcastable: logits_size=[16,4] labels_size=[16,2]\n",
      "\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_1463]]\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 43, in <module>\n",
      "    model_trainer.main()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_03_model_trainer.py\", line 22, in main\n",
      "    training.train()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\model_trainer.py\", line 75, in train\n",
      "    self.model.fit(\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n",
      "    File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 43, in <module>\n",
      "      model_trainer.main()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_03_model_trainer.py\", line 22, in main\n",
      "      training.train()\n",
      "    File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\model_trainer.py\", line 75, in train\n",
      "      self.model.fit(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n",
      "      loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n",
      "      return self.compiled_loss(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n",
      "      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n",
      "      losses = call_fn(y_true, y_pred)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n",
      "      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n",
      "      return backend.categorical_crossentropy(\n",
      "    File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\backend.py\", line 5565, in categorical_crossentropy\n",
      "      return tf.nn.softmax_cross_entropy_with_logits(\n",
      "Node: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\n",
      "logits and labels must be broadcastable: logits_size=[16,4] labels_size=[16,2]\n",
      "\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_1463]\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-15 15:52:46,378: INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]\n",
      "[2024-03-15 15:52:46,397: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 15:52:46,400: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 15:52:46,401: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 15:52:46,401: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2024-03-15 15:52:46,402: INFO: data_ingestion: Downloading data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 15:52:57,654: INFO: data_ingestion: Downloaded data from https://drive.google.com/file/d/1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n",
      "[2024-03-15 15:53:00,387: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2024-03-15 15:53:00,387: INFO: main: *******************]\n",
      "[2024-03-15 15:53:00,387: INFO: main: >>>>>> stage Prepare base model started <<<<<<]\n",
      "[2024-03-15 15:53:00,393: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-15 15:53:00,408: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-15 15:53:00,409: INFO: common: created directory at: artifacts]\n",
      "[2024-03-15 15:53:00,410: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "[2024-03-15 15:53:00,419: ERROR: main: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3).  Received: input_shape=[224, 224, 4]]\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 29, in <module>\n",
      "    prepare_base_model.main()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_02_prepare_base_model.py\", line 17, in main\n",
      "    prepare_base_model.get_base_model()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\prepare_base_model.py\", line 15, in get_base_model\n",
      "    self.model = tf.keras.applications.vgg16.VGG16(\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\applications\\vgg16.py\", line 137, in VGG16\n",
      "    input_shape = imagenet_utils.obtain_input_shape(\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\applications\\imagenet_utils.py\", line 367, in obtain_input_shape\n",
      "    raise ValueError(\n",
      "ValueError: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3).  Received: input_shape=[224, 224, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?/export=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ\n",
      "From (redirected): https://drive.google.com/uc?%2Fexport=download&id=1RE-2BwQGjQdUao9F8pvGEbZe2wZHFQVQ&confirm=t&uuid=d12ced37-a6c2-47c8-b6e7-c66026e4fe78\n",
      "To: d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\artifacts\\data_ingestion\\data.zip\n",
      "\n",
      "  0%|          | 0.00/49.0M [00:00<?, ?B/s]\n",
      "  2%|▏         | 1.05M/49.0M [00:00<00:06, 6.93MB/s]\n",
      "  4%|▍         | 2.10M/49.0M [00:00<00:06, 7.48MB/s]\n",
      "  6%|▋         | 3.15M/49.0M [00:00<00:05, 7.98MB/s]\n",
      "  9%|▊         | 4.19M/49.0M [00:00<00:05, 7.95MB/s]\n",
      " 11%|█         | 5.24M/49.0M [00:00<00:05, 8.36MB/s]\n",
      " 13%|█▎        | 6.29M/49.0M [00:00<00:04, 8.65MB/s]\n",
      " 15%|█▍        | 7.34M/49.0M [00:00<00:04, 8.79MB/s]\n",
      " 17%|█▋        | 8.39M/49.0M [00:01<00:04, 8.76MB/s]\n",
      " 19%|█▉        | 9.44M/49.0M [00:01<00:04, 8.94MB/s]\n",
      " 21%|██▏       | 10.5M/49.0M [00:01<00:04, 8.90MB/s]\n",
      " 24%|██▎       | 11.5M/49.0M [00:01<00:04, 8.56MB/s]\n",
      " 26%|██▌       | 12.6M/49.0M [00:01<00:04, 8.73MB/s]\n",
      " 28%|██▊       | 13.6M/49.0M [00:01<00:04, 8.68MB/s]\n",
      " 30%|██▉       | 14.7M/49.0M [00:01<00:03, 8.85MB/s]\n",
      " 32%|███▏      | 15.7M/49.0M [00:01<00:03, 9.03MB/s]\n",
      " 34%|███▍      | 16.8M/49.0M [00:01<00:03, 9.23MB/s]\n",
      " 36%|███▋      | 17.8M/49.0M [00:02<00:03, 9.15MB/s]\n",
      " 39%|███▊      | 18.9M/49.0M [00:02<00:03, 8.78MB/s]\n",
      " 41%|████      | 19.9M/49.0M [00:02<00:03, 8.57MB/s]\n",
      " 43%|████▎     | 21.0M/49.0M [00:02<00:03, 8.95MB/s]\n",
      " 45%|████▍     | 22.0M/49.0M [00:02<00:03, 8.94MB/s]\n",
      " 47%|████▋     | 23.1M/49.0M [00:02<00:03, 8.51MB/s]\n",
      " 49%|████▉     | 24.1M/49.0M [00:02<00:02, 8.91MB/s]\n",
      " 51%|█████▏    | 25.2M/49.0M [00:02<00:02, 9.19MB/s]\n",
      " 54%|█████▎    | 26.2M/49.0M [00:02<00:02, 9.07MB/s]\n",
      " 56%|█████▌    | 27.3M/49.0M [00:03<00:02, 8.86MB/s]\n",
      " 58%|█████▊    | 28.3M/49.0M [00:03<00:02, 9.09MB/s]\n",
      " 60%|█████▉    | 29.4M/49.0M [00:03<00:02, 9.22MB/s]\n",
      " 62%|██████▏   | 30.4M/49.0M [00:03<00:02, 8.98MB/s]\n",
      " 64%|██████▍   | 31.5M/49.0M [00:03<00:01, 8.96MB/s]\n",
      " 67%|██████▋   | 33.0M/49.0M [00:03<00:01, 9.60MB/s]\n",
      " 70%|██████▉   | 34.1M/49.0M [00:03<00:01, 9.71MB/s]\n",
      " 72%|███████▏  | 35.1M/49.0M [00:03<00:01, 9.41MB/s]\n",
      " 74%|███████▍  | 36.2M/49.0M [00:04<00:01, 9.12MB/s]\n",
      " 76%|███████▌  | 37.2M/49.0M [00:04<00:01, 9.05MB/s]\n",
      " 78%|███████▊  | 38.3M/49.0M [00:04<00:01, 9.13MB/s]\n",
      " 80%|████████  | 39.3M/49.0M [00:04<00:01, 9.04MB/s]\n",
      " 82%|████████▏ | 40.4M/49.0M [00:04<00:00, 8.95MB/s]\n",
      " 85%|████████▍ | 41.4M/49.0M [00:04<00:00, 9.03MB/s]\n",
      " 88%|████████▊ | 43.0M/49.0M [00:04<00:00, 9.02MB/s]\n",
      " 90%|████████▉ | 44.0M/49.0M [00:04<00:00, 9.20MB/s]\n",
      " 92%|█████████▏| 45.1M/49.0M [00:05<00:00, 8.16MB/s]\n",
      " 94%|█████████▍| 46.1M/49.0M [00:05<00:00, 6.46MB/s]\n",
      " 96%|█████████▋| 47.2M/49.0M [00:05<00:00, 6.80MB/s]\n",
      " 99%|█████████▊| 48.2M/49.0M [00:05<00:00, 7.24MB/s]\n",
      "100%|██████████| 49.0M/49.0M [00:05<00:00, 8.60MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 33, in <module>\n",
      "    raise e\n",
      "  File \"d:\\git\\Chest-Disease-Classification-from-Chest-CT-Scan-Image\\main.py\", line 29, in <module>\n",
      "    prepare_base_model.main()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\pipeline\\stage_02_prepare_base_model.py\", line 17, in main\n",
      "    prepare_base_model.get_base_model()\n",
      "  File \"d:\\git\\chest-disease-classification-from-chest-ct-scan-image\\src\\cnnClassifier\\components\\prepare_base_model.py\", line 15, in get_base_model\n",
      "    self.model = tf.keras.applications.vgg16.VGG16(\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\applications\\vgg16.py\", line 137, in VGG16\n",
      "    input_shape = imagenet_utils.obtain_input_shape(\n",
      "  File \"c:\\Users\\mayan\\.conda\\envs\\chest\\lib\\site-packages\\keras\\applications\\imagenet_utils.py\", line 367, in obtain_input_shape\n",
      "    raise ValueError(\n",
      "ValueError: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3).  Received: input_shape=[224, 224, 4]\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
